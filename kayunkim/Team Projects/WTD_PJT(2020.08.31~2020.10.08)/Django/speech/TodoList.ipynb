{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(filename) :\n",
    "    df = pd.read_csv(filename , encoding='CP949')\n",
    "    for i in df['total_x'] :\n",
    "        if',' in i :\n",
    "            i = i.replace(',' , '')\n",
    "    data = []\n",
    "    for i, row in df.iterrows():\n",
    "        data.append([row[0],row[1]])\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_data = preprocessing('train.csv')\n",
    "test_data = preprocessing('test.csv')\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def tokenize(doc):\n",
    "    # norm은 정규화, stem은 근어로 표시하기를 나타냄\n",
    "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('train_docs.json'):\n",
    "    with open('train_docs.json' , encoding='UTF8') as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open('test_docs.json' , encoding='UTF8') as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(tokenize(row[0]), row[1]) for row in train_data]\n",
    "    test_docs = [(tokenize(row[0]), row[1]) for row in test_data]\n",
    "    # JSON 파일로 저장\n",
    "    with open('train_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open('test_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens, name='NMSC')\n",
    "# print(len(text.tokens))\n",
    "# print(len(set(text.tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = [f[0] for f in text.vocab().most_common(1000)]\n",
    "\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [term_frequency(d) for d, _ in train_docs]\n",
    "train_y = [c for _, c in train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [term_frequency(d) for d, _ in test_docs]\n",
    "test_y = [c for _, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(train_x).astype('float32')\n",
    "y_train = np.asarray(train_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.asarray(test_x).astype('float32')\n",
    "y_test = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.4423 - binary_accuracy: 0.8233\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.1768 - binary_accuracy: 0.9217\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0897 - binary_accuracy: 0.9696\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0427 - binary_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0235 - binary_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0184 - binary_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0144 - binary_accuracy: 0.9957\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.0117 - binary_accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243bcb9b6d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(1000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 691us/step - loss: 0.1093 - binary_accuracy: 0.9647\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    print(\"[{}]는 업무일 확률 {:.2f}%.\\n\".format(review, score * 100))\n",
    "    if(score > 0.75):\n",
    "        print(\"업무O.\\n\")\n",
    "    else:\n",
    "        print(\"업무X.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[내일 오후 4시까지 햄버거 사오세요.]는 업무일 확률 99.99%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[요새 재미있는게 없을까?]는 업무일 확률 0.11%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[테스트 해볼까?]는 업무일 확률 70.22%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[와이어프레임 구성 완료했습니다]는 업무일 확률 99.36%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[오늘 3시까지 백엔드 일정추가 기능 완료해주세요!]는 업무일 확률 100.00%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[오늘까지 기획안 올려주세요]는 업무일 확률 99.99%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[피드백받은 부분 반영해서 ppt 수정하였습니다. ]는 업무일 확률 100.00%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[스토리 만들고, 스토리포인트 지정하고, 스프린트 시작해 주셔야 합니다! ]는 업무일 확률 99.93%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[스토리 만들고, 스토리포인트 지정하고, 스프린트 시작하겠습니다! ]는 업무일 확률 99.98%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[배고파 쩝쩝]는 업무일 확률 0.06%.\n",
      "\n",
      "업무X.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict('내일 오후 4시까지 햄버거 사오세요.')\n",
    "predict('요새 재미있는게 없을까?')\n",
    "predict('테스트 해볼까?')\n",
    "predict('와이어프레임 구성 완료했습니다')\n",
    "predict('오늘 3시까지 백엔드 일정추가 기능 완료해주세요!')\n",
    "predict('오늘까지 기획안 올려주세요')\n",
    "predict('피드백받은 부분 반영해서 ppt 수정하였습니다. ')\n",
    "predict('스토리 만들고, 스토리포인트 지정하고, 스프린트 시작해 주셔야 합니다! ')\n",
    "predict('스토리 만들고, 스토리포인트 지정하고, 스프린트 시작하겠습니다! ')\n",
    "predict('배고파 쩝쩝')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model.save('ToDoList.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('ToDoList.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n",
    "    score = float(new_model.predict(data))\n",
    "    print(\"[{}]는 업무일 확률 {:.2f}%.\\n\".format(review, score * 100))\n",
    "    if(score > 0.75):\n",
    "        print(\"업무O.\\n\")\n",
    "    else:\n",
    "        print(\"업무X.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[내일 오후 4시까지 햄버거 사오세요.]는 업무일 확률 99.99%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[요새 재미있는게 없을까?]는 업무일 확률 0.11%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[테스트 해볼까?]는 업무일 확률 70.22%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[와이어프레임 구성 완료했습니다]는 업무일 확률 99.36%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[오늘 3시까지 백엔드 일정추가 기능 완료해주세요!]는 업무일 확률 100.00%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[오늘까지 기획안 올려주세요]는 업무일 확률 99.99%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[피드백받은 부분 반영해서 ppt 수정하였습니다. ]는 업무일 확률 100.00%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[스토리 만들고, 스토리포인트 지정하고, 스프린트 시작해 주셔야 합니다! ]는 업무일 확률 99.93%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[스토리 만들고, 스토리포인트 지정하고, 스프린트 시작하겠습니다! ]는 업무일 확률 99.98%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[배고파 쩝쩝]는 업무일 확률 0.06%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[식당좀 알아봐주세요]는 업무일 확률 83.89%.\n",
      "\n",
      "업무O.\n",
      "\n",
      "[오늘 회식있는데 괜찮은 식당 좀 알아봐주세요]는 업무일 확률 0.46%.\n",
      "\n",
      "업무X.\n",
      "\n",
      "[괜찮은 식당 좀 알아봐주세요]는 업무일 확률 16.02%.\n",
      "\n",
      "업무X.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict2('내일 오후 4시까지 햄버거 사오세요.')\n",
    "predict2('요새 재미있는게 없을까?')\n",
    "predict2('테스트 해볼까?')\n",
    "predict2('와이어프레임 구성 완료했습니다')\n",
    "predict2('오늘 3시까지 백엔드 일정추가 기능 완료해주세요!')\n",
    "predict2('오늘까지 기획안 올려주세요')\n",
    "predict2('피드백받은 부분 반영해서 ppt 수정하였습니다. ')\n",
    "predict2('스토리 만들고, 스토리포인트 지정하고, 스프린트 시작해 주셔야 합니다! ')\n",
    "predict2('스토리 만들고, 스토리포인트 지정하고, 스프린트 시작하겠습니다! ')\n",
    "predict2('배고파 쩝쩝')\n",
    "predict2('식당좀 알아봐주세요')\n",
    "predict2('오늘 회식있는데 괜찮은 식당 좀 알아봐주세요')\n",
    "predict2('괜찮은 식당 좀 알아봐주세요')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
