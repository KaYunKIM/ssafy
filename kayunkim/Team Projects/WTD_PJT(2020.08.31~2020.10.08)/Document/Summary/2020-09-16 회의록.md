### 2020-09-16

STT: Google Cloud 제공 모델 사용

Text Summarization 모델

- Extractive

- Abstractive

1. TEXTRANK 
2.  FASTTEXT 먼저 공부 > WORD2VEC
3. 정확도 높이려면 pre training에는 BERT 사용

원문 --> (몇시 무슨일) 이런식으로

인풋 아웃풋이 모두 잘되있을 뿐더러

원문에 시간과 약속 장소 얘기없으면 그거에 맞게 뽑을거 없는 느낌으로다가 라벨링된거

- Unsupervised Learning 먼저
  - 한글 말뭉치 엄청 따와서 MECAB 형태소 분석기 돌려서 전처리된 데이터로 Pre Training
  - 라벨링된 데이터도로  Fine Training

- 월요일까지 공부 및 데이터 찾기
- STT 먼저 시작



데이터 찾는 사이트 추천

https://aihub.or.kr/aidata/8054 



PPT 내용

- MOTIVATION
  - 최대한 자동화를 해서 편하게 하자
- Idea
  - 미팅만들고 (와이프레임)
- Model
- Plan

